{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke-padmore/Source/flow-matching-mnist\n"
     ]
    }
   ],
   "source": [
    "%cd /home/luke-padmore/Source/flow-matching-mnist\n",
    "%autoreload 2\n",
    "from models.config import UNetConfig\n",
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing it instantiates correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder): Encoder(\n",
      "    (initial_conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (down_blocks): ModuleList(\n",
      "      (0): ConvDownblock(\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(8, 72, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(72, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (down): Sequential(\n",
      "          (0): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "      (1): ConvDownblock(\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(8, 72, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(72, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (down): Sequential(\n",
      "          (0): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "      (2): ConvDownblock(\n",
      "        (conv): Sequential(\n",
      "          (0): GroupNorm(8, 136, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(136, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (down): Sequential(\n",
      "          (0): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (up_blocks): ModuleList(\n",
      "      (0): ConvUpblock(\n",
      "        (upsampler): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(8, 520, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(520, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "      (1): ConvUpblock(\n",
      "        (upsampler): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(8, 264, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(264, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "      (2): ConvUpblock(\n",
      "        (upsampler): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (block): Sequential(\n",
      "          (0): GroupNorm(8, 136, eps=1e-05, affine=True)\n",
      "          (1): Conv2d(136, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): SiLU()\n",
      "          (3): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): SiLU()\n",
      "        )\n",
      "        (time_emb_mlp): Linear(in_features=32, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (bottleneck): Bottleneck(\n",
      "    (bottleneck): Sequential(\n",
      "      (0): GroupNorm(8, 272, eps=1e-05, affine=True)\n",
      "      (1): Conv2d(272, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): SiLU()\n",
      "      (3): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (5): SiLU()\n",
      "    )\n",
      "    (time_emb_mlp): Linear(in_features=32, out_features=16, bias=False)\n",
      "  )\n",
      "  (time_embedding_mlp): SinusoidalTimeEmbedding(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): SiLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cfg = UNetConfig(\n",
    "    channels=(1, 64, 128, 256),  \n",
    "    d_trunk=32,\n",
    "    d_concat=8,\n",
    "    group_norm_size=8,\n",
    "    d_time=128,\n",
    "    max_time_period=10000.0,\n",
    "    activation=\"silu\",\n",
    "    upsample_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "model = UNet.from_config(cfg)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.unet import UNet\n",
    "import sys\n",
    "from pathlib import Path \n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "batch_size = 64\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Pad(2,padding_mode='constant'),\n",
    "    transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "trainset = torchvision.datasets.MNIST(root = '/home/luke-padmore/Source/flow-matching-mnist/data',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transform)\n",
    "trainloader = DataLoader(trainset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = '/home/luke-padmore/Source/flow-matching-mnist/data',\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=transform)\n",
    "testloader = DataLoader(trainset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "cfg = UNetConfig(\n",
    "    channels=(1, 64, 128, 256),  \n",
    "    d_trunk=32,\n",
    "    d_concat=8,\n",
    "    group_norm_size=8,\n",
    "    d_time=128,\n",
    "    max_time_period=10000.0,\n",
    "    activation=\"silu\",\n",
    "    upsample_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "model = UNet.from_config(cfg).to(device)\n",
    "images = images.to(device)\n",
    "t = torch.rand((images.shape[0]),device=device).view(-1,1)\n",
    "out = model(images,t)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing sampling for an optuna trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optuna_models import HPTYaml\n",
    "from models.config import UNetConfig, OptimConfig\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_str = \"\"\"\n",
    "study:\n",
    "  study_name: \"test\"\n",
    "  direction: \"minimize\"\n",
    "  storage: \"sqlite:///optuna.db\"\n",
    "  n_trials: 1\n",
    "\n",
    "dataloader:\n",
    "  batch_size: 64\n",
    "  data_path: /home/luke-padmore/Source/flow-matching-mnist/data\n",
    "  num_workers: 4\n",
    "  shuffle: true\n",
    "  transform: \"default\"\n",
    "\n",
    "unet:\n",
    "  fixed:\n",
    "    max_time_period: 1000.0\n",
    "  choices:\n",
    "    channels:\n",
    "      type: categorical\n",
    "      choices:\n",
    "        - [1, 64, 128]\n",
    "        - [1, 64, 128, 256]\n",
    "    d_time:\n",
    "      type: categorical\n",
    "      choices: [64, 128, 256]\n",
    "    activation:\n",
    "      type: categorical\n",
    "      choices: [silu, relu, gelu]\n",
    "    upsample_mode:\n",
    "      type: categorical\n",
    "      choices: [nearest, bilinear, convtranspose]\n",
    "\n",
    "optim:\n",
    "  fixed:\n",
    "    name: adamw\n",
    "  choices:\n",
    "    lr:\n",
    "      type: float\n",
    "      low: 1e-5\n",
    "      high: 5e-4\n",
    "      log: true\n",
    "    weight_decay:\n",
    "      type: float\n",
    "      low: 1e-6\n",
    "      high: 1e-2\n",
    "      log: true\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-29 23:32:42,452] Using an existing study with name 'test' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetConfig(channels=[1, 64, 128, 256], d_trunk=32, d_concat=8, group_norm_size=8, d_time=64, max_time_period=1000.0, activation='gelu', upsample_mode='bilinear') OptimConfig(name='adamw', lr=0.00018585739010922318, weight_decay=0.00011993545279058418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke-padmore/miniconda3/envs/ml/lib/python3.12/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [1, 64, 128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/home/luke-padmore/miniconda3/envs/ml/lib/python3.12/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [1, 64, 128, 256] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "data = yaml.safe_load(yaml_str)\n",
    "hpt = HPTYaml.model_validate(data)\n",
    "study = optuna.create_study(\n",
    "    direction=hpt.opt_study_cfg.direction,\n",
    "    storage=hpt.opt_study_cfg.storage,\n",
    "    study_name=hpt.opt_study_cfg.study_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "trial = study.ask()\n",
    "unet_cfg, optim_cfg = hpt.sample(trial)\n",
    "print(unet_cfg, optim_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
